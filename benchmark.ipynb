{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['DATA_PATH'] = \"/root/work/data\"\n",
    "import matplotlib.pyplot as plt\n",
    "from invoke import task\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from model import build_dense, build_conv, build_dense_resid, build_ciresan_1, build_ciresan_4\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from lasagne import layers, objectives, updates\n",
    "from lasagnekit.datasets.mnist import MNIST\n",
    "from lasagnekit.datasets.helpers import split\n",
    "from lasagnekit.datasets.infinite_image_dataset import Transform\n",
    "from helpers import iterate_minibatches, flip, rotate_scale, rotate_scale_one, elastic_transform, elastic_transform_one\n",
    "from tabulate import tabulate\n",
    "from time import time\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from hp_toolkit.search import RandomSearch, DensityFitSearch\n",
    "\n",
    "from hp_toolkit.hp import Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TOM(BaseEstimator):\n",
    "    def __init__(self, **params):\n",
    "        params = params.copy()\n",
    "        self.n_components = params.get('n_components')\n",
    "        del params['n_components']\n",
    "        self.clf = Pipeline([\n",
    "            ('pca', PCA(n_components=self.n_components)),\n",
    "            ('clf', SVC(random_state=42, probability=True, **params)),\n",
    "        ])\n",
    " \n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    " \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    " \n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n",
    "\n",
    "class CHERTI(BaseEstimator):\n",
    "    def __init__(self, n_estimators=20, max_leaf_nodes=5):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    " \n",
    "    def fit(self, X, y):\n",
    "        self.clf = AdaBoostClassifier(\n",
    "            n_estimators=self.n_estimators, \n",
    "            base_estimator=DecisionTreeClassifier(max_leaf_nodes=self.max_leaf_nodes)\n",
    "        )\n",
    "        return self.clf.fit(X, y)\n",
    " \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    " \n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "w, h, c = 28, 28, 1\n",
    "print('Loading data...')\n",
    "\n",
    "def preprocess(data):\n",
    "    data = data * 2 - 1\n",
    "    return data.reshape((data.shape[0], c, w, h))\n",
    "\n",
    "train_full = MNIST(which='train')\n",
    "train_full.load()\n",
    "#train_full.X = preprocess(train_full.X)\n",
    "#train_full.X = train_full.X[0:128*10]\n",
    "\n",
    "train, valid = split(train_full, test_size=0.16667) # 10000 examples in validation set\n",
    "\n",
    "test = MNIST(which='test')\n",
    "test.load()\n",
    "#test.X = preprocess(test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params : {'n_estimators': 16, 'max_leaf_nodes': 87},  error :0.1401\n",
      "best params : {'n_estimators': 40, 'max_leaf_nodes': 30},  error :0.1286\n",
      "best params : {'n_estimators': 24, 'max_leaf_nodes': 83},  error :0.1188\n",
      "best params : {'n_estimators': 45, 'max_leaf_nodes': 45},  error :0.1143\n",
      "best params : {'n_estimators': 41, 'max_leaf_nodes': 90},  error :0.0946\n"
     ]
    }
   ],
   "source": [
    "def epsilon():\n",
    "    t = 1\n",
    "    while True:\n",
    "        eps = 1. / t\n",
    "        yield eps\n",
    "        t += 1\n",
    "        \n",
    "CLS = CHERTI\n",
    "\n",
    "if CLS == RandomForestClassifier:\n",
    "    hp = {\n",
    "        \"max_depth\": Param(initial=1, interval=[1, 20], type='int'),\n",
    "        \"n_estimators\": Param(initial=10, interval=[10, 300], type='int')\n",
    "    }\n",
    "if CLS == CHERTI:\n",
    "    hp = {\n",
    "        \"max_leaf_nodes\": Param(initial=1, interval=[1, 100], type='int'),\n",
    "        \"n_estimators\": Param(initial=10, interval=[10, 50], type='int')\n",
    "    }\n",
    "if CLS == TOM:\n",
    "    hp = {\n",
    "        \"C\": Param(initial=1, interval=[1, 1000], type='real', scale='log10'),\n",
    "        \"n_components\": Param(initial=100, interval=[10, 300], type='int'),\n",
    "        \"kernel\": Param(initial='rbf', interval=['rbf', 'poly', 'linear'], type='choice')\n",
    "    }\n",
    "\n",
    "\n",
    "#search = RandomSearch(hp)\n",
    "search = DensityFitSearch(hp, epsilon=epsilon, keep=10)\n",
    "\n",
    "smallest_err = np.inf\n",
    "\n",
    "for i in range(50):\n",
    "    params = search.sample_next()\n",
    "    clf = CLS(**params)\n",
    "    clf.fit(train.X, train.y)\n",
    "    err = (clf.predict(valid.X) != valid.y).mean()\n",
    "    search.update(params, err)\n",
    "    if err < smallest_err:\n",
    "        best_params = params\n",
    "        smallest_err = err\n",
    "        print(\"best params : {},  error :{}\".format(params, err))\n",
    "        best_model = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0939\n"
     ]
    }
   ],
   "source": [
    "err = (best_model.predict(test.X) != test.y).mean()\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
