{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'device=gpu'\n",
    "#os.environ['DATA_PATH'] = \"/work/data\"\n",
    "import matplotlib.pyplot as plt\n",
    "from invoke import task\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from model import build_dense, build_conv, build_dense_resid, build_ciresan_1, build_ciresan_4\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from lasagne import layers, objectives, updates\n",
    "from lasagnekit.datasets.mnist import MNIST\n",
    "from lasagnekit.datasets.helpers import split\n",
    "from lasagnekit.datasets.infinite_image_dataset import Transform\n",
    "from helpers import iterate_minibatches, flip, rotate_scale, rotate_scale_one, elastic_transform, elastic_transform_one\n",
    "from tabulate import tabulate\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minibatcher(fn, batchsize=1000):\n",
    "    def f(X, y):\n",
    "        results = []\n",
    "        for Xi, yi in iterate_minibatches(X, y, batchsize):\n",
    "            results.append(len(Xi) * fn(Xi, yi)) # assumes the result of fn is the average of something\n",
    "        return np.sum(results) / len(X)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = 1\n",
    "w = 28\n",
    "h = 28\n",
    "learning_rate = theano.shared(np.array(0.01).astype(np.float32))\n",
    "momentum = 0.9\n",
    "batchsize = 128\n",
    "\n",
    "X = T.tensor4()\n",
    "y = T.ivector()\n",
    "\n",
    "\n",
    "#net = build_ciresan_4(\n",
    "#    w=w, h=w, c=c, \n",
    "#    nb_outputs=10)\n",
    "\n",
    "\n",
    "#net = build_dense(\n",
    "#    w=w, h=w, c=c, \n",
    "#    nb_hidden=1000, \n",
    "#    nb_outputs=10, \n",
    "#    sample_alpha=False,\n",
    "#    nb_blocks=50, \n",
    "#    layer_per_block=2)\n",
    "\n",
    "net = build_conv(\n",
    "    w=w, h=h, c=c,\n",
    "    nb_filters=16,\n",
    "    filter_size=3,\n",
    "    nb_outputs=10,\n",
    "    nb_blocks=2,\n",
    "    layer_per_block=3,\n",
    "    pool=True)\n",
    "\n",
    "print('Compiling the net...')\n",
    "\n",
    "y_pred = layers.get_output(net, X)\n",
    "y_pred_detm = layers.get_output(net, X, deterministic=True)\n",
    "#predict_fn = theano.function([X], y_pred)\n",
    "\n",
    "loss = objectives.categorical_crossentropy(y_pred, y).mean()\n",
    "\n",
    "loss_detm = objectives.categorical_crossentropy(y_pred, y).mean()\n",
    "y_acc_detm = T.eq(y_pred_detm.argmax(axis=1), y).mean()\n",
    "\n",
    "loss_fn = theano.function([X, y], loss_detm)\n",
    "loss_fn = minibatcher(loss_fn, batchsize=1000)\n",
    "\n",
    "acc_fn = theano.function([X, y], y_acc_detm)\n",
    "acc_fn = minibatcher(acc_fn, batchsize=1000)\n",
    "\n",
    "params = layers.get_all_params(net, trainable=True)\n",
    "grad_updates = updates.momentum(loss, params, learning_rate=learning_rate, momentum=momentum)\n",
    "#grad_updates = updates.adam(loss, params, learning_rate=learning_rate)\n",
    "\n",
    "train_fn = theano.function([X, y], loss, updates=grad_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Loading data...')\n",
    "\n",
    "def preprocess(data):\n",
    "    data = data * 2 - 1\n",
    "    return data.reshape((data.shape[0], c, w, h))\n",
    "\n",
    "train_full = MNIST(which='train')\n",
    "train_full.load()\n",
    "train_full.X = preprocess(train_full.X)\n",
    "#train_full.X = train_full.X[0:128*10]\n",
    "\n",
    "train, valid = split(train_full, test_size=0.16667) # 10000 examples in validation set\n",
    "\n",
    "test = MNIST(which='test')\n",
    "test.load()\n",
    "test.X = preprocess(test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment(X):\n",
    "    X = X[:, 0]\n",
    "    X = rotate_scale(X, min_angle=-7, max_angle=7, min_scale=0.85, max_scale=1.15, n_jobs=10)\n",
    "    X = elastic_transform(X, min_alpha=36, max_alpha=38, min_sigma=5, max_sigma=6, n_jobs=10)\n",
    "    X = X[:, None, :, :]\n",
    "    X = X.astype(np.float32)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "lr_decay = 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_sims = []\n",
    "lr_sim = lr\n",
    "for i in range(100):\n",
    "    lr_sims.append(lr_sim)\n",
    "    lr_sim *= lr_decay\n",
    "plt.plot(lr_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb_epochs = 100\n",
    "data_augment = False\n",
    "learning_rate.set_value(np.array(lr).astype(np.float32))\n",
    "\n",
    "print('Training...')\n",
    "\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    data_aug_time = []\n",
    "    train_time = []\n",
    "    \n",
    "    # Data augmentation\n",
    "    t = time()\n",
    "    if data_augment:\n",
    "        train_X_full = augment(train.X)\n",
    "    else:\n",
    "        train_X_full = train.X\n",
    "    data_aug_time.append(time() - t)\n",
    "\n",
    "    train_y_full = train.y\n",
    "    for train_X, train_y in iterate_minibatches(train_X_full, train_y_full, batchsize):\n",
    "        # Train one mini=batch\n",
    "        t = time()\n",
    "        train_fn(train_X, train_y)\n",
    "        train_time.append(time() - t)\n",
    "    \n",
    "    \n",
    "    stats = OrderedDict()\n",
    "    stats['train_loss'] = loss_fn(train.X, train.y)\n",
    "    stats['valid_losss'] = loss_fn(valid.X, valid.y)\n",
    "    stats['train_acc'] = acc_fn(train.X, train.y)\n",
    "    stats['valid_acc'] = acc_fn(valid.X, valid.y)\n",
    "    stats['data_aug_time'] = np.sum(data_aug_time)\n",
    "    stats['train_time'] = np.sum(train_time)\n",
    "    stats['epoch'] = epoch\n",
    "    \n",
    "    history.append(stats)\n",
    "    print(tabulate([stats], headers=\"keys\"))\n",
    "    \n",
    "    lr = learning_rate.get_value()\n",
    "    lr = lr * lr_decay\n",
    "    learning_rate.set_value(np.array(lr).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_acc = [h['train_acc'] for h in history]\n",
    "test_acc = [h['valid_acc'] for h in history]\n",
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_acc = acc_fn(test.X, test.y)\n",
    "print(1-test_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_layers = layers.get_all_layers(net)\n",
    "input_var = all_layers[0].input_var\n",
    "for l in all_layers:\n",
    "    f = theano.function([input_var], layers.get_output(l, input_var))\n",
    "    h = f(train.X)\n",
    "    print(l, h.shape)\n",
    "    plt.hist(h.flatten())\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
