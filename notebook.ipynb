{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['DATA_PATH'] = \"/root/work/data\"\n",
    "import matplotlib.pyplot as plt\n",
    "from invoke import task\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from model import build_dense, build_conv, build_dense_resid, build_ciresan\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from lasagne import layers, objectives, updates\n",
    "from lasagnekit.datasets.mnist import MNIST\n",
    "from lasagnekit.datasets.infinite_image_dataset import Transform\n",
    "from helpers import iterate_minibatches, flip, rotate_scale, rotate_scale_one, elastic_transform, elastic_transform_one\n",
    "from tabulate import tabulate\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling the net...\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 100\n",
    "c = 1\n",
    "w = 28\n",
    "h = 28\n",
    "learning_rate = theano.shared(np.array(0.001).astype(np.float32))\n",
    "momentum = 0\n",
    "batchsize = 128\n",
    "\n",
    "X = T.tensor4()\n",
    "y = T.ivector()\n",
    "\n",
    "net = build_ciresan(\n",
    "    w=w, h=w, c=c, \n",
    "    nb_outputs=10)\n",
    "#net = build_dense(\n",
    "#    w=w, h=w, c=c, \n",
    "#    nb_hidden=500, \n",
    "#    nb_outputs=10, \n",
    "#    nb_blocks=4, layer_per_block=2)\n",
    "\n",
    "#net = build_conv(\n",
    "#\tw=w, h=h, c=c,\n",
    "#\tnb_filters=16,\n",
    "#\tfilter_size=5,\n",
    "#\tnb_outputs=10,\n",
    "#\tnb_blocks=2,\n",
    "#\tlayer_per_block=3,\n",
    "#\tpool=True\n",
    "#)\n",
    "\n",
    "print('Compiling the net...')\n",
    "\n",
    "y_pred = layers.get_output(net, X)\n",
    "y_pred_detm = layers.get_output(net, X, deterministic=True)\n",
    "#predict_fn = theano.function([X], y_pred)\n",
    "\n",
    "loss = objectives.categorical_crossentropy(y_pred, y).mean()\n",
    "\n",
    "loss_detm = objectives.categorical_crossentropy(y_pred, y).mean()\n",
    "y_acc_detm = T.eq(y_pred_detm.argmax(axis=1), y).mean()\n",
    "\n",
    "loss_fn = theano.function([X, y], loss_detm)\n",
    "acc_fn = theano.function([X, y], y_acc_detm)\n",
    "\n",
    "params = layers.get_all_params(net, trainable=True)\n",
    "grad_updates = updates.momentum(loss, params, learning_rate=learning_rate, momentum=momentum)\n",
    "train_fn = theano.function([X, y], loss, updates=grad_updates)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "\n",
    "def preprocess(data):\n",
    "    return data.reshape((data.shape[0], c, w, h))\n",
    "\n",
    "train = MNIST(which='train')\n",
    "train.load()\n",
    "train.X = preprocess(train.X)\n",
    "train.X = train.X[0:128]\n",
    "train.y = train.y[0:128]\n",
    "\n",
    "test = MNIST(which='test')\n",
    "test.load()\n",
    "test.X = preprocess(test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "learning_rate.set_value(np.array(lr).astype(np.float32))\n",
    "\n",
    "print('Training...')\n",
    "\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    data_aug_time = []\n",
    "    train_time = []\n",
    "    for train_X, train_y in iterate_minibatches(train.X, train.y, batchsize):\n",
    "        t = time()\n",
    "        train_X = rotate_scale(\n",
    "            train_X[:, 0],\n",
    "            min_angle=-15, max_angle=15,\n",
    "            min_scale=0.85, max_scale=1.15)\n",
    "        train_X = elastic_transform(\n",
    "            train_X, min_alpha=36, max_alpha=38, min_sigma=5, max_sigma=6)\n",
    "        data_aug_time.append(time() - t)\n",
    "        t = time()\n",
    "        train_X = train_X[:, None, :, :]\n",
    "        train_fn(train_X, train_y)\n",
    "        train_time.append(time() - t)\n",
    "    stats = OrderedDict()\n",
    "    stats['train_loss'] = loss_fn(train.X, train.y)\n",
    "    stats['test_loss'] = loss_fn(test.X, test.y)\n",
    "    stats['train_acc'] = acc_fn(train.X, train.y)\n",
    "    stats['test_acc'] = acc_fn(test.X, test.y)\n",
    "    stats['data_aug_time'] = np.sum(data_aug_time)\n",
    "    stats['train_time'] = np.sum(train_time)\n",
    "    stats['epoch'] = epoch\n",
    "    \n",
    "    history.append(stats)\n",
    "    print(tabulate([stats], headers=\"keys\"))\n",
    "    \n",
    "    lr = learning_rate.get_value()\n",
    "    #lr *= 0.99\n",
    "    learning_rate.set_value(np.array(lr).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_acc = [h['train_acc'] for h in history]\n",
    "test_acc = [h['test_acc'] for h in history]\n",
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
